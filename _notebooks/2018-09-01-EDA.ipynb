{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "painted-breakfast",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "> First steps in exploration\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Johann Augustine\n",
    "- image: images/NYC-harbor.jpg\n",
    "- categories: [lambda-school, data-science]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-hughes",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "> Exploratory Data Analysis (EDA) is the critical process of conducting preliminary investigations on data in order to discover patterns, detect anomalies, test hypotheses, and validate assumptions using summary statistics and graphical representations.\n",
    "\n",
    "When we first start with a new dataset, we often perform exploratory data analysis. The discoveries that we make during this stage of the process drive how we treat our data, the models we choose, the approach we take to analyzing our data, and, in large part, the entirety of our data science methodology and next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-inclusion",
   "metadata": {},
   "source": [
    "## Load a CSV dataset using pandas read_csv\n",
    "\n",
    "We will be working with data in many different forms throughout our careers. But before we can start to do anything with that data, we need to load it into our workspace. \n",
    "\n",
    "> Tip: Start with [Google colab](https://colab.research.google.com) and ease your way into a working local environment on your machine. \n",
    "\n",
    "### Pandas\n",
    "You are likely already familiar with the Python data analysis library pandas. We'll provide a quick overview here and then work through some examples in the next section.\n",
    "\n",
    "The pandas library includes a wide range of data analysis and manipulation tools. It also offers data structures (Series, DataFrames) that are designed to function well with a variety of data types, including tabular data, time series data, and matrix data (for example, columns with different data types) using read.csv to read files\n",
    "\n",
    "To begin, we'll look at one of the most commonly used pandas methods: read csv. This method can be used to read data in the comma separated value (csv) format: each row's values are separated by a comma, and new lines (rows) begin on the next line. A csv file can be loaded from a URL or read from a locally stored file on your device. \n",
    "\n",
    "There are many options for using read csv, as there are for several other pandas methods. To learn more about these, start with some of the official documentation at https://pandas.pydata.org/docs/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-omega",
   "metadata": {},
   "source": [
    "#### Load a CSV dataset from a URL using pandas read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "matched-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas with the standard alias\n",
    "import pandas as pd\n",
    "\n",
    "# Set a variable to the URL you copied above\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/tic-tac-toe/tic-tac-toe.data'\n",
    "\n",
    "# Read or load the data\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-india",
   "metadata": {},
   "source": [
    "#### Load a CSV dataset from a local file using pandas read_csv\n",
    "\n",
    "When working with data sets, you'll find many of them conveniently stored on online at various locations (UCI Repository, Kaggle, etc.). But you'll often want to download a data set to store it on your local computer. This makes it easy to use tools on your computer to view and edit the file in addition to having a copy safely stored on your hard drive.\n",
    "\n",
    "The pandas `read_csv()` method can also read in locally saved files. Instead of providing the URL, you will use the path to the file. Think of the path like the address of the file: it's a list of directories leading to the file location. An example path might look like /Users/myname/Documents/data_science/tic-tac-toe.data where the last part of the path is the file name. To read in a local file with pandas, you can use the following code (assume pandas has been imported):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in an example file (from a example user's Downloads folder)\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/home/username/Downloads/tic-tac-toe.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-interpretation",
   "metadata": {},
   "source": [
    "## Use basic Pandas functions for Exploratory Data Analysis-EDA\n",
    "\n",
    "Exploratory data analysis (EDA) is a very important part of learning to be a data scientist. And something that experienced data scientists do on a regular basis. We'll be using some of the numerous tools available in the pandas library. Earlier in the module, we learned how to load data sets into notebooks. So now that we have all this data, what do we do with it?\n",
    "\n",
    "### Basic Information\n",
    "\n",
    "There are a few methods to look at your DataFrame quickly and get an idea of what's inside. Here are a few of the most common with descriptions of what each method does:\n",
    "\n",
    "| method        | description                                 |\n",
    "|:---------------|:--------------------------------------------|\n",
    "|`df.shape`     | display the size (x, y) |\n",
    "|`df.head()`    | display the first n rows (default=5) |\n",
    "|`df.tail()`    | display the last n rows (default=5) |\n",
    "|`df.describe()`| display the statistics of numerical data types  |\n",
    "|`df.info()`    | display the number of entries (rows), number of columns, and the data types |\n",
    "\n",
    "### Column-specific\n",
    "\n",
    "Sometimes we don't want to look at the entire DataFrame and instead want to focus on a single column or a few columns. There are a few ways to select a column but we'll mainly use the column name. If we have a DataFrame called `df` and a column named \"column_1\" we could select just a single column by using `df[\"column_1\"]`. Once we have a single column selected, we can use some of the following methods to get more information.\n",
    "\n",
    "| method            | description                                 |\n",
    "|:-------------------|:--------------------------------------------|\n",
    "|`df.columns`     | print a list of the columns |\n",
    "|`df['column_name']`| select a single column ( returns a Series) |\n",
    "|`df['column_name'].value_counts()`| count the number of `object` and `boolean` occurrences |\n",
    "|`df.sort_values(by='column_name')` | sort the values in the given column\n",
    "|`df.drop()` | remove rows or columns by specifying the label or index of the row/column |\n",
    "\n",
    "### Missing Values\n",
    "\n",
    "There is a lot of data out there, and along with that comes the unavoidable fact that some of it will be messy. This means that there will be missing values, \"not-a-number\" (NaN) occurrences, and problems with zeros not being actually zero. Fortunately, there are a number of pandas methods that make dealing with the mess a little easier.\n",
    "\n",
    "| method            | description                                       |\n",
    "|:-------------------|:--------------------------------------------------|\n",
    "|`df.isnull().sum()` | count and sum the number of null occurrences (NaN or None) |\n",
    "|`df.fillna()` | fill NaN values in a variety of ways |\n",
    "|`df.dropna()` | remove values that are NaN or None; by default removes all rows with NaNs|\n",
    "\n",
    "\n",
    "The above methods cover a lot of ground but we'll work through examples using them on a data set. First, we need some data. We'll use the M&Ms data set for this, because it's small and contains both numeric and Object (string) data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "devoted-bloom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(816, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>color</th>\n",
       "      <th>diameter</th>\n",
       "      <th>mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>blue</td>\n",
       "      <td>16.20</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>brown</td>\n",
       "      <td>16.50</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>orange</td>\n",
       "      <td>15.48</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>brown</td>\n",
       "      <td>16.32</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>yellow</td>\n",
       "      <td>15.59</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type   color  diameter  mass\n",
       "0  peanut butter    blue     16.20  2.18\n",
       "1  peanut butter   brown     16.50  2.01\n",
       "2  peanut butter  orange     15.48  1.78\n",
       "3  peanut butter   brown     16.32  1.98\n",
       "4  peanut butter  yellow     15.59  1.62"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reads in the data from the website\n",
    "url_mms = 'https://tinyurl.com/mms-statistics'\n",
    "df = pd.read_csv(url_mms)\n",
    "\n",
    "# Looks at the dimensions of your data:\n",
    "print(df.shape)\n",
    "(816, 4)\n",
    "\n",
    "# Looks at first 5 rows of your data:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-profession",
   "metadata": {},
   "source": [
    "`df.info()` prints information about a DataFrame including the index dtype and columns, non-null values and memory usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "downtown-animation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 816 entries, 0 to 815\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   type      816 non-null    object \n",
      " 1   color     816 non-null    object \n",
      " 2   diameter  816 non-null    float64\n",
      " 3   mass      816 non-null    float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 25.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# DataFrame information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-deviation",
   "metadata": {},
   "source": [
    " We can use describe to print out the statistics for the numeric columns using `df.describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "australian-institute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diameter</th>\n",
       "      <th>mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>816.000000</td>\n",
       "      <td>816.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.171912</td>\n",
       "      <td>1.419632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.220001</td>\n",
       "      <td>0.714765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.230000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.220000</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.600000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.300000</td>\n",
       "      <td>1.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.880000</td>\n",
       "      <td>3.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         diameter        mass\n",
       "count  816.000000  816.000000\n",
       "mean    14.171912    1.419632\n",
       "std      1.220001    0.714765\n",
       "min     11.230000    0.720000\n",
       "25%     13.220000    0.860000\n",
       "50%     13.600000    0.920000\n",
       "75%     15.300000    1.930000\n",
       "max     17.880000    3.620000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-orientation",
   "metadata": {},
   "source": [
    "`df.columns` prints the column labels of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assured-myanmar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'color', 'diameter', 'mass'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-equality",
   "metadata": {},
   "source": [
    "Say we dont need a column any more, we can drop it with `df.drop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proprietary-application",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>color</th>\n",
       "      <th>diameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>blue</td>\n",
       "      <td>16.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>brown</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>orange</td>\n",
       "      <td>15.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>brown</td>\n",
       "      <td>16.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>yellow</td>\n",
       "      <td>15.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type   color  diameter\n",
       "0  peanut butter    blue     16.20\n",
       "1  peanut butter   brown     16.50\n",
       "2  peanut butter  orange     15.48\n",
       "3  peanut butter   brown     16.32\n",
       "4  peanut butter  yellow     15.59"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the mass column\n",
    "df.drop(columns='mass').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-stationery",
   "metadata": {},
   "source": [
    "And lastly say we want to look at all the different values a certain column has. We can do so with \n",
    "`df['column name'].value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "seventh-failing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plain            462\n",
       "peanut butter    201\n",
       "peanut           153\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the values in the 'type' column\n",
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d6fd2-0cd7-48e5-913e-577e39794a47",
   "metadata": {},
   "source": [
    "### Fin\n",
    "\n",
    "I don't ever remember all these techniques. So I either google what I need or head over to [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) to refresh my memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-preference",
   "metadata": {},
   "source": [
    "> Note: This post is a reflection of my first week at Lambda School. For a more rigorous introduction to python, pandas and EDA, you can reference [Python for Data Analysis](https://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1491957662/ref=pd_lpo_14_t_0/137-0388884-4997641?_encoding=UTF8&pd_rd_i=1491957662&pd_rd_r=f83c895f-1fc3-4edd-b74e-723ab0f64044&pd_rd_w=mcYQh&pd_rd_wg=nIRhM&pf_rd_p=337be819-13af-4fb9-8b3e-a5291c097ebb&pf_rd_r=44MJ6GR5N2YKKFSYHP26&psc=1&refRID=44MJ6GR5N2YKKFSYHP26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d6668-a60b-4f8f-9d4c-1e1a0f2f1651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
